{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78dbba4b",
   "metadata": {},
   "source": [
    "# Tensor Basics\n",
    "- Jackson Cown\n",
    "- 6/7/22\n",
    "\n",
    "\n",
    "- var_t indicates a tensor stored in CPU memory\n",
    "- var_g indicates a tensor stored in GPU memory\n",
    "- var_a indicates a NumPy array stored in CPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7a75dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd281ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e3505f",
   "metadata": {},
   "source": [
    "## Creating Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a87c1e8",
   "metadata": {},
   "source": [
    "#### Starting with native lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70207978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Native Python List: [1.0, 2.0, 1.0]\n",
      "\n",
      "First Element: 1.0\n",
      "Second Element: 2.0\n",
      "Third Element: 1.0\n",
      "\n",
      "Updated List: [1.0, 2.0, 3.0]\n",
      "Last Element: 3.0\n"
     ]
    }
   ],
   "source": [
    "# Starting with a basic python list, then moving to torch tensors\n",
    "a_list = [1.0, 2.0, 1.0]\n",
    "print(f'Native Python List: {a_list}\\n')\n",
    "\n",
    "# List index syntax\n",
    "print(f'First Element: {a_list[0]}')\n",
    "print(f'Second Element: {a_list[1]}')\n",
    "print(f'Third Element: {a_list[2]}')\n",
    "\n",
    "# Update Python List\n",
    "a_list[2] = 3.0\n",
    "print(f'\\nUpdated List: {a_list}')\n",
    "print(f'Last Element: {a_list[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4b5914",
   "metadata": {},
   "source": [
    "#### Constructing our first tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce9e2a16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch Tensor: tensor([1., 1., 1.])\n",
      "\n",
      "First Element: 1.0\n",
      "Second Element: 1.0\n",
      "Third Element: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Basic torch tensor\n",
    "a_tensor = torch.ones(3) # populate 1d tensor of size 3\n",
    "print(f'Torch Tensor: {a_tensor}\\n')\n",
    "\n",
    "# Tensor index syntax - note that f-strings autoconvert to float\n",
    "print(f'First Element: {a_tensor[0]}')\n",
    "print(f'Second Element: {a_tensor[1]}')\n",
    "print(f'Third Element: {a_tensor[2]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2546bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "1.0\n",
      "\n",
      "Updated Tensor: tensor([1., 1., 2.])\n",
      "Last Element: 2.0\n"
     ]
    }
   ],
   "source": [
    "# Once again, note how the behavior differs without the f-string syntax\n",
    "print(a_tensor[1])\n",
    "print(float(a_tensor[1]))\n",
    "\n",
    "# Indexed assignment for tensors\n",
    "a_tensor[2] = 2.0\n",
    "print(f'\\nUpdated Tensor: {a_tensor}')\n",
    "print(f'Last Element: {a_tensor[-1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7a2cab",
   "metadata": {},
   "source": [
    "#### Tensor Aside:\n",
    "- PyTorch Tensors allow us to manipulate and maintain collections of floating-point numbers\n",
    "- Tensors can be indexed similar to native Python lists but they function completely differently under the hood.\n",
    "- They provide convenient structure for generating unique intermediate representations of data during the forward process\n",
    "- Tensors are the fundamental building block of PyTorch. By mimicking the numpy API, they provide easy to use representations of floating-point data that allow for highspeed operations on contiguous memory.\n",
    "\n",
    "\n",
    "- A few notable tensor capabilities:\n",
    "    - Ability to perform fast operations on GPUs\n",
    "    - Distribute operations on multiple devices or machines\n",
    "    - Keep track of the computation graph that created the respective tensor, which is essential for AutoGrad\n",
    "\n",
    "\n",
    "#### Essense of Tensors\n",
    "- Torch tensors and numpy arrays are views over contiguous memory blocks containing *unboxed*C numeric types rather than Python objects.\n",
    "    - Each element in a 32-bit (4-byte) float. (Most of the time)\n",
    "    - Storing a 1D tensor of 1,000,000 float numbers will require exactly 4,000,000 contiguous bytes, plus a small overhead for metadata (such as dimensions and numeric type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcf1d45",
   "metadata": {},
   "source": [
    "#### Example: List of coordinates to represent a geometrical object\n",
    "- 2D triangle with vertices at coordinates (4, 1), (5, 3), and (2, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f096e31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4., 1., 5., 3., 2., 1.])\n",
      "First Point: (4.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "# init points of triangle in a simple 1D tensor\n",
    "points = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])\n",
    "print(points)\n",
    "\n",
    "# Getting coords of first point\n",
    "print(f'First Point: {float(points[0]), float(points[1])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b49bf20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n",
      "\n",
      "2D array shape: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# init same points of triangle in a 2D tensor by passing in a list of lists\n",
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "print(points)\n",
    "\n",
    "# Outputing the shape\n",
    "print(f'\\n2D array shape: {points.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "13c6629e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# init a multidimensional Tensor with zeros or ones\n",
    "points = torch.zeros(3, 2)\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46b09ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n",
      "\n",
      "Row indexing: tensor([4., 1.])\n",
      "Column indexing: tensor([4., 5., 2.])\n",
      "Item indexing: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Indexing multidimensional tensor\n",
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "print(points)\n",
    "print(f'\\nRow indexing: {points[0]}')\n",
    "print(f'Column indexing: {points[:, 0]}')\n",
    "print(f'Item indexing: {points[0, 1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec06c2c0",
   "metadata": {},
   "source": [
    "#### Tensor views\n",
    "- The output of tensor indexing presents another tensor that represents a different view of the same underlying data.\n",
    "- This change of view avoid computationally wasteful operations, like copying the indexed elements to a new tensor.\n",
    "- In the case of the row index example above, it returns a new 1D tensor with a size of 2, referencing the first row in the ```points``` tensor\n",
    "- More on how tensors are stored and viewed later this chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dc4663",
   "metadata": {},
   "source": [
    "### Indexing Tensors\n",
    "- Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee0c593",
   "metadata": {},
   "source": [
    "#### Native Python indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de1be5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Nums:\n",
      "[0, 1, 2, 3, 4, 5]\n",
      "\n",
      "All Elements: [0, 1, 2, 3, 4, 5]\n",
      "Elements 1 to 4 exclusive: [1, 2, 3]\n",
      "Elements 1 to end of list inclusive: [1, 2, 3, 4, 5]\n",
      "Elements 0 to element 4 exclusive: [0, 1, 2, 3]\n",
      "Elements 0 to last element exclusive: [0, 1, 2, 3, 4]\n",
      "Elements 1 to 4 exclusive, steps of 2: [1, 3]\n"
     ]
    }
   ],
   "source": [
    "# init native python list\n",
    "some_list = list(range(6))\n",
    "print('List of Nums:')\n",
    "print(some_list)\n",
    "\n",
    "print(f'\\nAll Elements: {some_list[:]}')\n",
    "print(f'Elements 1 to 4 exclusive: {some_list[1:4]}')\n",
    "print(f'Elements 1 to end of list inclusive: {some_list[1:]}')\n",
    "print(f'Elements 0 to element 4 exclusive: {some_list[:4]}')\n",
    "print(f'Elements 0 to last element exclusive: {some_list[:-1]}')\n",
    "print(f'Elements 1 to 4 exclusive, steps of 2: {some_list[1:4:2]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9af116",
   "metadata": {},
   "source": [
    "#### Torch Tensor Indexing\n",
    "- PyTorch tensors use the same notation as native Python\n",
    "- We can use range indexing for each of the tensor's dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7611f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n",
      "\n",
      "All rows after the first: \n",
      "tensor([[5., 3.],\n",
      "        [2., 1.]])\n",
      "\n",
      "All rows after the first; all columns: \n",
      "tensor([[5., 3.],\n",
      "        [2., 1.]])\n",
      "\n",
      "All Rows after the first; first column: \n",
      "tensor([5., 2.])\n",
      "\n",
      "Adds a dimension of size 1, just like unsqueeze: \n",
      "tensor([[[4., 1.],\n",
      "         [5., 3.],\n",
      "         [2., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "# using 2D tensor created earlier\n",
    "print(points)\n",
    "\n",
    "print(f'\\nAll rows after the first: \\n{points[1:]}')\n",
    "print(f'\\nAll rows after the first; all columns: \\n{points[1:, :]}')\n",
    "print(f'\\nAll Rows after the first; first column: \\n{points[1:, 0]}')\n",
    "print(f'\\nAdds a dimension of size 1, just like unsqueeze: \\n{points[None]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad6629d",
   "metadata": {},
   "source": [
    "#### PyTorch also features a powerful form of indexing, called *advanced indexing*\n",
    "- More on this next chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701e10a3",
   "metadata": {},
   "source": [
    "### Named Tensors\n",
    "- The dimensions of a tensor typically represent something like pixel locations or color channels.\n",
    "- When we want to index into a tensor, we need to remember the ordering of the dimesions and write our indexing accordingly.\n",
    "- Keeping track of dimensions and their orders can be one of the more challenging aspects of PyTorch\n",
    "    - Note: Yea I find this to be one of, if not, the most annoying aspect of programming in pytorch. It would be great to find a way to cope with these difficulties.\n",
    "    \n",
    "\n",
    "#### Image example\n",
    "- Imagine we have a 3D tensor called img_t (image tensor stored in CPU memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f57f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init a 5x5 image with 3 color channels\n",
    "img_t = torch.randn(3, 5, 5) # Shape [channels, rows, columns]\n",
    "# We want to convert it to grayscale\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780784dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
