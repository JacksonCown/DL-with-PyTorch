{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "192452ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import imageio.v2 as imageio # Throws warning otherwise\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8043602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bef43ef",
   "metadata": {},
   "source": [
    "# Using a Neural Network to Fit the Data\n",
    "- Jackson Cown\n",
    "- 7/5/2022\n",
    "\n",
    "\n",
    "This chapter covers:\n",
    "- Nonlinear activation functions as the key difference compared to linear models\n",
    "- Working with PyTorch's ```nn``` module\n",
    "- Solving a linear-fit problem with a neural network\n",
    "\n",
    "\n",
    "Post Chapter Summary:\n",
    "- Neural networks can be automatically adapted to specialize themselves on the problem at hand.\n",
    "- Neural networks allow easy access to the analytical derivatives of the loss with respect to any parameter in the model, which makes evolving the parameters very efficient. Thanks to its automated differentiation engine, PyTorch provides such derivatives effortlessly.\n",
    "- Activation functions around linear transformations make neural netowrks capable of appoximating highly nonlinear function, at the same time keeping them simple enough to optimize.\n",
    "- The ```nn``` module together with ther tensor standard library provide all the building blocks for creating neural networks.\n",
    "- To recognize overfitting, it's essential to maintain the training set of data points separate from the validation set. There's no one recipe to combat overfitting, but getting more data, or more variability in the data, and resorting to simpler models are good starts.\n",
    "- Anyone doing data science should be plotting all the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c07e9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
